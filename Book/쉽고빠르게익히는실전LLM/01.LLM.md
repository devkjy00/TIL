- LLM은 대부분 트랜스포머 아키텍처에서 파생된 AI모델이다
	- 방대한 양의 텍스트 데이터로 학습
	
- LLM과 트랜스포머의 성공은 여러 아이디어의 결합 덕분이다
	-  어텐션, 전이학습, 신경망의 스케일링등 

- 발전 과정
	1. 신경망 언어 모델
	2. Word2vec을 이용한 의미 인코딩
	3. Seq2seq + 어텐션
	4. (현재) 트랜스 포머 + LLM

- 셀프 어텐션 
	- 단어 간의 장거리 종속성(long-range dependendcies)와 문맥관계를 포착할 수 있게 해주는 종류의 어텐션 계산
		- 각 단어의 중요도(어텐션 가중치)를 계산
		- 트랜스포머 아키텍쳐에서 사용

> 이 책의 목적은 트랜스포머를 사용할 수 있도록 하는것

### LLM 정의, 특징
- LLM이란 자연어 처리 및 이해를 위해 대규모로 훈련된 모델로 텍스트를 이해하고 생성할 수 있다

- LLM 두가지 언어 모델링의 조합이 될 수 있는 언어 모델이다
	- 자기회귀 언어 모델 : 이전 토큰으로 다음 토큰을 예측하도록 훈련
		- AI answer : 이야기를 하면서 다음에 어떤 말을 할지 예측하는 것과 비슷해.
		- 특정 토큰만 볼 수 있도록 마스크가 토큰들을 가린다

	- 자동 인코딩 언어 모델 : 손상된 입력 내용으로 기존 문장을 재구성하도록 훈련
		- AI answer : 마치 사진을 흑백으로 변환하고 다시 컬러로 복구하는 것과 비슷해, 중요한 정보를 유지하면서도 데이터를 간소화하고, 필요할 때 다시 원래의 형태로 되돌릴 수 있어
		- 데이터를 작게 압축해서 중요한 부분만 남기고, 다시 풀어내어 원래 데이터를 재구성

	- Seq2seq 
		- 인코더 : 원시 텍스트를 분리하고 벡터로 변환하는 업무
		- 디코더 : 다음 올 최적의 토큰을 예측
		- AI answer : 한 언어로 쓰인 책을 읽고 그 내용을 이해합니다(인코더). 그리고 그 내용을 다른 언어로 번역하여 새로운 책을 작성합니다(디코더)

### LLM 작동 원리
- 사전 훈련 : 대량의 텍스트 데이터를 이용해서 특정 언어 모델링 작업을 하는 것
	- 예시
		- BERT는 위키백과와 대량의 소설모음으로 사전 훈련됬다
		- BERT는 마스크된 언어 예측과 다음 문장 예측으로 사전 훈련되었다
		
	- **LLM은 사전훈련으로 차이를 만들기 때문에 경쟁우위를 위해서 독점적인 데이터 소스에서 훈련된다**

- 전이 학습 : 머신 러닝 결과를 활용, 관련 작업의 성능을 향상시키는 기술
	- AI answer : 뛰어난 일식 요리 전문가는 그가 배운 기술과 경험을 한식, 중식, 양식 요리에도 적용할 수 있습니다
	- 일반적으로 비지도 학습으로 사전훈련후 지도학습으로 훈련, 데이터로 모델을 파인튜닝한다
		- ? 비지도 학습 : '답'이 주어지지 않은 데이터를 사용하여 모델을 학습
			- AI answer : 고객들의 구매 기록을 사용하여 유사한 구매 패턴을 찾아내거나 비슷한 그룹을 묶는 클러스터링 알고리즘을 학습할 때 사용됩니다.

		- ? 지도 학습 : '답'이 주어진 데이터를 사용하여 모델을 학습
			- AI answer : 이메일이 스팸인지 아닌지를 분류하는 모델을 학습할 때, 각 이메일이 스팸인지 여부를 나타내는 레이블이 함께 제공됩니다.

	- [전이학습 왜?](https://newindow.tistory.com/254)
		- 성능이 좋은 딥러닝 모델을 만드는 최고의 방법은 바로 많은 수의 데이터를 확보하는 것이다. 하지만 데이터의 수가 많지 않거나 데이터를 확보하는데 많은 비용이 드는 경우가 존재할 수 있다.
		- 이를 해결하기 위해 Transfer Learning(전이학습)을 이용
		- 새롭게 만들어진 모델을 이용해 Fine Tuning(파인튜닝)을 진행

- 파인 튜닝 : 상대적으로 작은 크기의 데이터 셋에서의 재학습을 통해서 파라미터를 조정, 정확도를 향상시키는 방법
	- [파인튜닝의 개념](https://velog.io/@tjdtnsu/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EC%B4%88-%EC%A0%84%EC%9D%B4-%ED%95%99%EC%8A%B5-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0)
		- 전이 학습과 미세 조정(fine-tuning)을 헷갈릴 수 있는데, 전이 학습은 모델을 효율적으로 학습하기 위한 하나의 큰 접근 방법이며, 미세 조정은 전이 학습에서 사용되는 기법 중 하나라고 볼 수 있겠습니다.
		
	- AI Square에서 사용하는 파인튜닝 방법
		- Low Rank Adaptation : 모델의 특정 부분을 "저랭크(low rank)"로 설정해서 모델 파라미터의 수를 줄이는 방법 중 하나
			- AI answer : SUV를 타면 골목길(적은 리소스)을 지나가기 힘들기 때문에 오토바이로 갈아타는 것
				- 모델이 더 빠르게 학습되고, 적은 메모리와 계산 리소스를 사용하여 새로운 작업을 수행할 수 있게 됩니다.

- 어텐션 : 가장 중요한 정보를 우선시 할 수 있게 해줘서 각 부분의 중요성을 예측할 수 있게 하는 계산
	- AI answer : 노래를 들을 때 특정 소리(가수, 드럼, 피아노...)에만 집중해서 듣는 것과 같습니다
	- 모든 입력을 동등하게 처리하던 과거와 달리 어텐션을 사용해서 LLM은 동적으로 입력 시퀀스의 특정 부분에 집중할 수 있게 되었고 더 나은 예측을 할 수 있다
	- ***트랜스 포머 아키텍쳐의 차별점은 어텐션을 사용해서 토큰 간의 장거리 의존성과 관계를 정의할 수 있다는 것이다***

- 임베딩 : 토큰을 기계가 읽을 수 있는 값으로 변환하는 것
	- AI answer :
		- 문장: "나는 사과를 좋아해"
		- 임베딩 : 숫자의 벡터 형태로 표현된다
			- "나는": [0.2, 0.4, 0.1, 0.9]
			- "사과를": [0.5, 0.8, 0.3, 0.7]
			- "좋아해": [0.6, 0.2, 0.9, 0.4]
		
	- 위치 임베딩 : 토큰의 위치를 임베딩
	- 토큰 임베딩 : 토큰의 의미를 임베딩
	- LLM은 사전훈련을 기반으로 임베딩을 학습하고 파인튜닝으로 다시 업데이트할 수 있다

- 토큰화 : 텍스트를 가장 작은 이해 단위인 토큰으로 분해하는 과정
	- [토큰화 시뮬레이션](https://platform.openai.com/tokenizer)
	- LLM은 본적없는 단어들을 처리해야 한다, 그래서 텍스트를 어떻게 토큰화 하는지도 중요하다
	- chatGPT API는 사용자가 사용한 토큰 수를 계산해서 요금을 책정하고 있다

- 정렬 + RLHF
	- 언어 모델에서의 정렬은 얼마나 정확한 답변인지가 기준이 된다
	- 인간 피드백 기반 강화 학습(RLHF) : 사람의 피드백으로 성능을 향상
		- 전통적인 지도학습의 일부 한계를 극복시킨다
			- 지도학습은 답이 명시적인 레이블로 저장되어있는 데이터가 필요해서 동적으로 변하거나 개인화된 학습이 어렵다

- 번역작업 : LLM이 왜 번역을 잘하는지 

### LLM 종류
- BERT : 어텐션 메커니즘을 사용하는 자동 인코딩 모델
	- 많은 양의 텍스트를 빠르게 처리, 대량의 텍스트를 처리할 때 적합하다
	
- GPT : 어텐션 메커니즘을 사용하는 자기회귀 모델
	- 자유롭게 텍스트를 작성할수 있는 능력이 필요할 때 적합하다

- T5 : 순수한 인코더/디코더 트랜스포머 모델
	- 텍스트를 빠르게 처리하고 자유로운 텍스트를 생성하는 능력 모두 필요로 할 떄 적합하다


### 도메인 특화 LLM
- 생물학, 금융과 같은 특정 주제 영역에서 훈련된 모델

### LLM을 이용한 어플리케이션 
- 전통적인 자연어 처리(NLP) 작업
	-  텍스트 분류 : 주어진 텍스트 조각에 레이블을 할당하는 것
		- 주로 감정 분석에서 흔히 사용된다(긍정적, 부정적, 중립)
		- 미리 정의된 카테고리로 분류할 수 있다
	- 번역 작업 : 의미와 맥락을 유지 하면서 텍스트를 다른 언어로 번역하는 것
		- 사전 훈련과 어텐션 계산 덕분에 쉽게 수행할 수 있다
- 자유로운 텍스트 생성
	- 블로그, 이메일, 논문등 다양하나 텍스트를 작성할 수 있다

- 정보 검색/신경망 의미 기반 검색
	- 정보를 동적으로 최신 상태로 유지하기 위해서 벡터 데이터베이스를 사용한다
- 챗봇