# 빅데이터 처리기술
> 학습내용
- 분산 파일 시스템, 분산 데이터 처리 아키텍처
- 데이터 저장/처리 시스템
- 빅 데이터 처리 기술 

### 데이터 저장 시스템(기술)
- 정의
	- 데이터 집합을 저장하고 관리하는 시스템
	- CAP 이론
		- 일관성(Consistency)
		- 가용성(Availablilty)
		- 지속성(Partition Tolerance)

- 데이터 저장방식의 구분
	- 데이터 베이스
		- RDBMS, NoSQL
		- 데이터웨어하우스 
	- 분산파일 시스템
		- HDFS, GFS

- 데이터 유형별 저장 시스템
	|유형|데이터 종류|저장 시스템|
	|-|-|-|
	|정형|RDB, 스프레드 시트|RDBMS|
	|반정형|HTML, XML, JSON 등|RDBMS, NoSQL|
	|비정형|문서, 이미지, 오디오, 비디오|NoSQL, 분산파일시스템(HDFS)|
	- RDBMS : 객체를 테이블로 구성해서 테이블 간의 관계로 정의
		- 장단점
			- 무결성, 정확성 보장
			- 정규화된 테이블과 소규모 트랜잭션
			- 확장성에 한계
			- 클라우드 분산환경에 부적합

	- NoSQL(분산형 DB)
		- 장단점
			- 무결성, 정확성 보장하지 않음
			- 웹 환경의 다양한 정보를 검색, 저장 가능
			- 노드의 추가 및 삭제, 데이터 분산에 유연
			
		- 특징
			- No 스키마 : 키값을 이용해서 다양한 형태의 데이터를 저장
				- 저장 방식은 열, 값, 문서, 그래프등 네가지 기반
			- 탄력성 : 시스템 일부 장애시에도 클라이언트가 시스템에 접근가능
			- 질의기능 : 수십대에서 수천대 규모로 구성된 시스템에서도 데이터의 특성에 맞게 효율적으로 데이터를 검색/처리하는 API제공
			- 캐싱 : 메모리 기반 캐싱으로 빠른 응답속


	- 데이터웨어하우스
		- 여러 데이터베이스에 축적된 데이터를 공통의 형식으로 변환하여 일원적으로 관리
	
	-  ***분산 파일 시스템***
		- 서로 다른 컴퓨터에 데이터를 분산시키고 네트워크로 공유, 오류가 발생하면 복구하는 기능
			- 대용량, 분산, 데이터 집중형 애플리케이션 지원
		- GFS(Google File System)
			- 구글 검색엔진을 위한 최적화 파일 시스템

		- HDFS(Hadoop Distributed File System)
			- 하둡의 대표적 파일 시스템
			- 파일을 블록 단위로 나눠서 보관(64mb)
			- 블록을 다중 노드에 분산해서 보관
			- 하나의 블록을 여러노드에 복제(replication)
				- 하나의 블록이 없어져도 복구 가능

### 데이터 처리 시스템(기술)
- ETL(Extract, Trasform, Load)
	- 데이터들을 data warehouse, data mart로 이동시키는 process

- 분산 데이터 처리
- 분산 파일 시스템에 저장된 데이터를 처리하는 기술
		- 아파치 계열 : HADOOP, Spark, PIG, HIVE
		- 비 아파치 계열 : Mrjob(python), infoSphere(IBM)
	
	- Spark
		- 하둡의 단점을 개선 중간 데이터를 메모리에 저장해서 반복되는 작업에서 더 빠르다

### 빅데이터 처리 기술 정리
- 빅데이터 용량과 처리시간
	- ~ GB, 초분시 정도의 시간 -> RDBMS 적용 영역
	- GB ~, 시일 정도의 시간 -> Hadoop 적용 영역
- 분산 파일 처리 시스템의 아키텍처
	- 추상적 구조 : 마스터 노드와 여러 슬레이브 노드의 결합
	- 물리적 구조 : 마스터 서버(JobTracker, NameNode)와 슬레이브 서버(TaskTracker, DataNode)가 네트워크로 연결

		
# 아파치 스파크
> 아파치 스파크의 탄생, 특징

### 아파치 스파크의 탄생
- 2009 버클리에서 출범 -> 2010 오픈소스로 공개 -> 2013 아파치 스파크 출시
- 스파크 개발 커뮤니티에서 컨트리뷰터와 커미터들을 통해서 개발됨
	
### 스파크 특징
- 통합 컴퓨팅 엔진
- 클러스터 환경에서 데이터를 병렬로 처리하는 라이브러리 집합
	- 병렬 처리 : 저렴한 여러 서버를 네트워크로 연결해서 처리하는 방식

- 스파크 철학
	- 통합
		- 다양향 데이터 분석 작업(SQL, 머신러닝, 스트림 등)을 같은 연산엔진과 일관성 있는 API로 수행할 수 있도록 설계
		- 예 : 쿼리로 데이터를 읽고 머신러닝 모델을 평가하는 것을 하나로 병합하여 처리
	
	- 컴퓨팅 엔진
		- 데이터 저장 위치에 상관없이 처리에 집중하도록 설계
		- 하둡 저장소(HDFS)와 호환
		- 클라우드 환경에서도 사용 가능(하둡은 불가)
	
	- 라이브러리
		- 표준 라이브러리 제공
		- 저장소 시스템을 위한 커넥터, 머신러닝 알고리즘등 
	
- 하둡과 차이점
	- 인메모리 실행
		- 하둡 : 맵리듀스 job의 결과를 다른 job에서 사용하기 위해 HDFS에 저장
		- 스파크 : job에 필요한 데이터를 메모리에 캐시로 저장
	
	- 사용 편의성 : 스파크는 내부적으로 구현이 많이 되어있어서 짧은 코드로 구현가능
	- 스파크 생태계 : HDFS와 YARN없이 사용할 수 있다
	
