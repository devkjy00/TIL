# 스파크 기본 아키텍처(1)
> 학습내용
- 기본 아키텍처
- 트랜스포메이션, 액션, 스파크 세션
- 스파크 데이터프래임의 파티션과 익스큐터

### 스파크 아키텍처
- 스파크 : 클러스터의 데이터 처리작업을 관리/조율하는 프레임워크
- 클러스터 매니저 : submit을 처리할 자원을 할당해서 결과를 반환시켜준다
	- standalone 클러스터 매니저
	- 하둡 YARN
		- 스파크의 내부적으로 하둡이 동작한다
	- 메소스(mesos)

- 스파크 애플리케이션
	- 드라이버 프로세스 : 스파크 애플리케이션의 수명주기 동안 관련 정보를 모두 유지한다
		- 전반적인 익스큐터 프로세스의 작업과 관련된 분석, 배포, 스케줄링
	- 익스큐터 : 실행자

### 스파크 세션
- 스파크 세션과 언어 API간 관계
	- 파이썬이나 R 코드를 JVM에서 실행할 수 있는 코드로 변환

- 파이썬을 이용한 스파크 세션 생성 예
	- 대화형 모드 : 자동 생성됨
	- 사용자 어플리케이션 
		```py
		# 스파크 세션으로 데이터 프레임 생성
		my_range = spark.range(1000).toDF("number")
		```

### DataFrame
- DataFrame : 테이블의 데이터를 행과 열로 표현
- 파티션 : DF가 저장되는 구역
	- 익스큐터와 다대다 관계로 연결

### 트랜스포메이션
- 트랜스포메이션 : DataFrame을 변경하기위해 변경방법을 스파크에 알리는 명령어
	- 논리적 실행 계획을 세운다
	- 지연연산을 사용, 동작이 실행될 때(액션) 한번에 실행한다

- 작업 유형
	- 1:1(좁은 트랜스포메이션) : 하나의 데이터프레임에서 다른 하나의 데이터프레임으로
		- 파이프라이닝...
	
	- 1:N(넓은 트랜스포메이션) : 하나의 데이터프레임에서 여러 데이터프레임으로
		- 셔플...

- 함수
	- map(func) : 함수의 반환값으로 새로운 분산 데이터셋 반환
		- flatmap(func)
	- filter(func) : 함수의 참으로 선택된 데이터로 분산 데이터셋 반환
	- distinct([작업갯수]) : 유일무이한 작업만 선택해서 인자로 전달, 분산 데이터셋 반환

### 액션
- 액션 : 실제 연산을 수행하는 명령어
- 함수
	- reduce(func) : 데이터셋 원소를 총합요약, func 함수의 인자는 2개
	- take(n) : 첫 n개의 원소로 배열 생성
	- collect() : 배열로 모든 원소를 반환(메모리 용량 사전확인필요)
	- takeOrdered(n, key=func) : 함수의 반환값 기준 or 오름차순으로 n개의 원소를 반환

- 작동과정
	- 액션을 시작하면 스파크 잡(job)이 시작

> 트랜스포메이션(중간연산), 액션(최종연산) -> 자바의 스트림?


# 스파크 기본 아키텍처
> 학습내용
- 데이터프레임 처리과정
- 데이터프레임과 SQL

### 데이터 프레임 처리과정
1. pyspark로 대화형 모드 진입
2. 데이터 읽기
	```py
	>> import os
	>> data2015 = spark.read\
	... .option("inferSchema", "true")\
	... .option("header", "true")\
	... .csv("파일경로")

	>> data2015.take(1) # 데이터 하나 가져오기
	```
	- spark.read... : 로컬의 파일을 읽어 데이터 프레임을 반환
	- take(n) : 데이터프레임의 레코드를 n개 출력

3. 데이터 정렬, 수집
	```py
	data2015.sort("count").explain()
	```
	- .sork(필드) : 특정 필드(컬럼)로 정렬하는 트랜스포메인션으로 실행은 되지 않는다
	- .explain : 실행계획 읽기
	- spark.conf.set("spark.sql.shuffle.partitions", "n") : 스파크의 셔플 출력 파티션 수를 n개로 조정

### 데이터프레임과 SQL
- DF를 테이블로 만들어서 처리
	- createOrReplaceTempView : 데이터 프레임을 테이블이나 뷰로 만들기
	- spark.sql("""sql문""") : 실행계획 읽기
	- .groupBy() : 데이터프레임으로 그룹으로 구분

> 스파크의 실행계획은 방향성 비순환 그래프로 설계되어 있고 액션이 호출되면 실행된다
