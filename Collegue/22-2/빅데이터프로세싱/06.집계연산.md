# 집계함수
> 학습내용
- 카운트 함수
- 순서 함수
- 통계산출 함수


### 함수
- 카운트 함수
	- count() : 특정 컬럼을 지정
		- 액션이 아닌 트랜스포메이션으로 동작
	- countDistinct()
	- approx_count_distinct(필드, 최대추정오류율)
		- 근사치만으로도 유의미한 상황에서 사용
		- 빠르게 결과 도출해서 대규모 데이터셋을 사용하기 유용
	
- 순서 함수 : first(), last()
- 통계산출 함수
	- min(), max()
	- avg()
	- sum() : 필드가 수치형 타입일때 가능
		- sumDistinct()

# 그룹화와 윈도우 함수
### 그룹화
```
>>> df.groupBy("column1").agg(
... expr("count(column2)")).show()
```

### 윈도우 함수
- 데이터의 특정 '윈도우(window)'대상으로 고유의 집계 연산 수행
- 데이터의 '윈도우' => 현재 데이터에 대한 참조를 사용해 정의
- 윈도우 명세(window specification) => 함수에 전달될 로우 결정
- 프레임 : 로우 그룹 기반의 테이블

- 메서드
	- partitionBy() : 그룹을 어떻게 나눌지 결정
	- orderBy() : 파티션 정렬 방식 정의
	- rowsBetween(from, to) : 입력된 로우의 참조 기반으로 프레임에 로우가 포함될 수 있는지 결정

```
>>> from pyspark.sql.window import Window
>>> windowSpec = Window\
... .partitionBy("CustomerId", "date")\
... .orderBy(desc("Qunatity"))
... .rowsBetween(Window.unboundedPreceding, Window.currentRow)
```
