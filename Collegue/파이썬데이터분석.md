
# 1주차
>주피터			
- [ipyhon매직명령어]
>객체				
- [모든 숫자, 문자열, 자료구조, 함수, 클래스, 모듈 등이 파이썬에서 객체]
>주피터자동메소드 	
- [ . 입력후에 tab을 누르면 쓸수있는 메소드를 출력해준다]
>a=10			
- [a에 저장이 아니라 10이라는 값을 a가 가리킨다,  분리된 각각]
>getattr(객체명,클래스명)	
- [속성과 메서드값을 반환]
>덕 타이핑.   		
- [객체가 어떤 메서드나 행동을 지원하는지 확인하는 것]
>iter(객체)			
- [해당 객체가 순환가능한지, 복수의 값인지 확인]
>모듈임포트		
- [import ~ 는 파일명 = 클래스명 으로생각하면된다
-  from ~ import ~ 는 모듈명 없이 사용가능 하지만 지양]
>이항연산자		
- [a//b(나머지를 뺀 몫,정수형), a**b(제곱), ^(exclusive or), a is(not) b(값이 아닌 같은 객체를 참조하는지 비교(주소가 값은 값), == 와 다르다) ] 
>뮤터블,이뮤터블  	
- [값을 변경가능한 객체 ‘뮤터블’, 변경불가능 객체 ‘이뮤터블’(튜플)]

# 2주차
>스칼라형			
- [하나의 값을 저장하는 자료형/ int, float, bool]
>“”” “”” 			
- [개행문자나 여러줄에 걸친 문자열은 세개의 작은따옴표나 큰따옴표로 둘러싼다]
>x.count(“”)		
- [인자가 몇번 나오는지를 반환]
>r”/“				
- [역슬래시가 포함된 문자열을 그대로 해석할 때 문자열 앞에 r을 붙인다]
>{0:.2f}			
- [0번째:소수점2째 자리까지 표시하는 소수]
>x_utf8			
- [유니코드 문자열을 urf-8바이트 표현으로 변환, .decode(’utf-8’)로 되돌릴 수 있다]
>None			
- [null값, is None으로 null값을 확인 해서 참,거짓으로 반환(함수에서 값을 반환하지 않으면 묵시적으로 none을 반환)]
>datetime			
- [date,time정보를 함께 제공하는 모듈]
>삼항표현식		
- [x = a if y esle b]
>튜플				
- [튜플안 리스트,사전,집합 변경가능, 연산자로 튜플합치거나곱하기 가능
- 튜플값 분리하기 tup = 1,2,3 / a,b,c = tup 하면 각각 대입됨
- a, b = b, a 로 값을 서로 바꿀 수도 있다, *x로 지정되지않은 값 전부 대입
- count : 같은값을 새서 반환, 
- index : 주어진 값이 놓인 위치반환]
>bisect			
- [이진탐색,정렬 유지 
- .bisect(list,2):2가 정렬된 추가될위치반환
- .insort(list,2): 정렬위치에 값이 추가됨]

# 3주차
>sorted(x)			
- [정렬된 새로운 순차자료형 리스트를 반환]
>zip(x,y)			
- [복수의 리스트를 묶어서 zip object 생성, 리스트길이가 가장짧은 게 기준
- a,b = zip(*x)로 다시 풀어낼수도 있다]
>reversed			
- [순차 자료형을 역순으로 반환한다]
>dict 형			
- [del, .pop(해당값 반환후삭제), .keys(), .values(), .update(다른사전과 합침)
- zip(x,y) 객체를 인자로 받아서 생성가능, key값은 hash가능한 객체만 선언가능]
>hash()			
- [인자의 해쉬값을 반환, 해쉬는 자료의 중복되지않고 규칙없는 고유한값(암호)]
>집합				
- [리스트를 집합에 넣으려면 튜플로 변경]
>list,set,dict표기법	
- [{set,dict}or[list] 내용 i for i in x if i (collection객체)]
>map				
- [map(함수명, 인자)를 실행]
>키워드인자		
- [def x (a,b=3):기본값, 일반인자 뒤에 선언]
>함수도객체다		
- [x = [str.strip, 함수명, 함수명]리스트에저장,사용]

>익명함수,람다함수	
- [a = lambda x : x+2 , x가 인자 : 뒤가 반환문 a(x) 형태로 실행시킨다
- lambda 예약어로 정의, 값을 반환하는 단순한 한 문장으로 이루어진 함수]
>커링	
```py			
def a(x,y): 
    b = lambda y: a(10,y)
    return x+y
```
- 일부인자만 취해서 새로운 함수를 만드는 기법
>이터레이터		
- [순차자료를 하나씩 차례대로 반환하는 동작(for..)
- a = iter(b) 하면 list b의 키값가짐 이터객체]
>제너레이터		
- [순차자료를 발생시켜 차례로 반환하는 함수 한번이아닌 여러차례 반환하는 것
- 함수에서 return 대신 이터레이터와함께 yield예약어 사용, 값은 제너레이터 객체
- for x in gener: 으로 함수를 호출한다]
>제너레이터표기법	
- [gen_obj = (a+2 for a in b if x)로 제너레이터 함수를 한줄 생성,함수인자로 사용
- sum(x+2 for x in a)와 같이 사용가능]

# 4주차(NumPy ndarray)
>NumPy			
- [단일 산술 배열 데이터를 다루는 데 특화되어있다, 같은 데이터타입]
>1,2,3차원	배열		
- [vector, matrix, tensor]
>ndarray			
- [같은 자료형만 키값으로 가짐, 벡터화 연산 가능, 메모리 최적화 속도 향상]
>ndarray 메소드	
- [array(list) : 대입된 리스트를 ndarray형으로 변환해서 반환
- ndim : 배열의 차원수 반환
- shape : 각 차원의 크기를 튜플형태로 반환
- dtype : 키 값의 자료형을 반환
- zeros(index) : 값이 0으로 채워진 배열 생성
- ones(index) : 값이 1으로 채워진 배열 생성
- empty(index) : 초기화되지않은 임의의 값을 가진 배열 생성
- arange(10) : 0~9까지의 값을 가진 1차원 배열 )
- astype(np.float64) : dtype을 다른 자료형으로 변환해서 반환,(ndarray.dtype)으로 다른 객체의 자료형을 참조해서 같은 자료형으로 변환 가능 
- copy() : 배열값을 복사해서 반환(깊은 복사)
- reshape((4,6)) 배열의크기를 다시 초기화 순서대로 값 대입]
>벡터화			
- [배열에 대해서 for루프를 사용하지 않고 데이터를 일괄 처리하는 것
- arr + arr2 ,,, 등 간단하게 계산, arr > arr2 는 블리언 배열로 반환]
>슬라이싱			
- [arr[5:8] = 12 -> 해당값들이 전부 12가 된다
- arr_slice = arr[0:1]로 view 객체 생성(얕은 복사), 원본 객체를 가리키게 된다
- arr_slice[1]=5 -> 원본의 값을 변화 시킨다
- arr[:2, 1:]으로 2차원 슬라이싱, arr[:2,2]으로 스칼라값을 주면 1차원배열으로 값반환] 

>블리언 배열		
- [ arr == ‘x’  / ndarray에 자료를 비교연산 후 블리언값을 배열로 반환
- 블리언 배열을 색인(인덱스)로 사용할 수 있다
- data[arr==‘x’]이면 비교연산이 True 값을 가지는 인덱스의 값을 반환
- != , ~ 를 사용해서 조건절을 부인할 수 있고 &, | 로 논리연산가능 ]
>팬시색인			
- [arr[[5,3],[6,2]] 특정순서대로 값을 대입, -를 대입하면 뒤에서부터 계산
- arr[[1,2]][:,[5,8]] 슬라이싱 각인덱스에 다 적용 1행에 5번째,8번째값반환]
>배열전치(전치행렬)	
- [arr.T /데이터를 복사하지 않고 배열의 축이 바뀐 뷰를 반환(행,열교체)]
>행렬의 내적(곱하기)	
- [np.dot / 곱하는 행렬의 앞 행과 뒷 열이같아야한다,전치필요(3*6)*(6*3)=(3*3) ]
>다차원배열 전치		
- [arr.transpose(1,0,2)/ 면:0,행:1,열:2 을 의미
- 모든 첫행의 값은 첫면이 된다 둘째행은 둘째 면으로  arr[1][2][3]->[2][1][3]]

# 5주차(NumPy)
>유니버셜 함수		
- [ufanc, 배열의 각 원소를 빠르게 처리하는 함수, 벡터화 시키는 래퍼함수(pandas에도 적용가능)]
- np.sqrt(arr)	
    - [모든 값의 루트값을 배열로반환(루트는 제곱나누기 9루트 = 3)]
- np.exp(arr)	
    - [무한지수값(파이처럼)]
>이항유니버셜함수	
- [2개의 인자를 취하는 유니버셜 함수]
- np.modf(arr)	
    - [소수값을 정수부분과 소수부분을 나눠서 2개의 값 반환]
- np.sqrt(arr,x)	
    - [저장할 변수이름을 추가로 지정 가능]
>단,이항유니버셜함수	
- [p.223]
>배열지향프로그래밍	
- [벡터화를 통해서 초고속으로 연산이 가능하다]
>np.where()		
- [(arr>0,x,y) 조건문이 참이면 x반환,거짓이면 y반환 
				x if a else y 와 같은 삼항식의 벡터화된 버전이다, 조건문을 연산가능]

>수학,통계 메서드	
- [arr.메서드(axis=1(열)) :같은 열의 모든 행의 연산값을 구한다(0:행)
- np.메서드(배열): 모든 원소의 연산값을 구한다	
    - sum: 원소의 합/ mean: 산술 평균/ std, var: 표준편차, 분산/min, max: 최소값, 최대값/ argmin, argmax: 최소값인덱스,최대값인덱스 /cumsum:누적합/ cumprod:누적곱/ sort: 정렬(분8위수를구하기쉽다)]
>블리언 메서드		
- [(arr>0).sum(): 양수인 원소의 개수
- arr.any(): 하나이상의 값이 True인지
- arr.all(): 모든 원소가 True인지]
>집합관련함수		
- [np.unique(arr) : 배열내에서 중복된 원소 제거하고 정렬
- in1d(arr,[1,2,3]): arr 내에 해당 값을 포함하는지 블리언배열반환
- p.246(함수)]

>파일 입출력		
- [열기:np.load(’dir.npy’)/ 복수불러오기사용: arr[‘a’] dict형식
- 저장: np.save(‘dir.npy’, arr)/ 복수저장:np.savez(‘dir.npz’, a=arr, b=arr)
- 파일압축: np.savez_compressed(‘dir.npz’,a=arr’’’’) 
    - 반복되는 값이 많을때 효과적]
>선형대수			
- [행렬곱: x.dot(y) 과 np.dot(x,y) 과 x@y 사용	
- np.ones(3(행)): 1을 원소로가지는 행렬]
>행렬처리함수		
- [from numpy.linalg import inv, qr
- X.T(전치).dot(X) : 전치행렬과 원래행렬을 곱함,  
- inv(X) : 역행렬 반환
- p.258(함수) ]
>난수 생성			
- [np.random.normal(size=int) : 난수값을 반환]
>시드값			
- [np.random.seed(1234): 전역난수 시드값이용
- np.random.RandomState : 다른 난수 생성기로 부터 격리된 또다른 난수생성
- p.262(함수)]

# 6주차(Pandas)
>Pandas			
- [표 형식의 데이터나 다앙한 형태의 데이터를 다루는데 초점이 맞춰져 있다
- import pandas as pd ,  from pandas import Series, DataFrame(자주써서 그냥임포트)]
>Series			
- [1차원 배열 같은 자료구조(모든 Numpy자료형을 담을 수 있다)
- arr = pd.Series([4,7,5,2], Index=[~~]) : 초기화하고 인덱스명을 만들수 있다 ]
>Series객체활용		
- [arr[arr>0]  불리언배열을 사용해서 값을 걸러낼수 있다
- arr*2 키값을 곱해줄수 있다
- dict = {‘a’:1, ‘b’:2} -> arr = pd.Series(dict) 로 초기화하거나 색인값을 따로 지어가능
- pd.insull(arr), pd,notnull() 	블리언 배열 반환
- arr.name = ‘~~’ 시리즈 객체의 이름을 입력할 수있다/ .index.name 색인의 이름도 입력]
				
>DataFrame		
- [pd.DataFrame(dict, columns=[열 카테고리(나이,이름~~)], index=[행 카테고리(1번,2번~~)])
- 표같은 형식의 자료구조를 가진다, 로우와 컬럼에대한 색인을 가짐, 사전형객체를 값으로 가진다
- frame[‘~~’] or frame.~~ 로 같은 키값을 가지는 값에 접근할수 있다.
- frame.loc[two(인덱스명)] or frame.iloc[2(인덱스)] 로 같은 밸류인덱스값에 해당하는 값에 접근]
>DataFrame값대입	
- [지정된 컬럼(키값)에 스칼라값이나 배열(같은길이)값을 대입할수 있다
- pd.Series([1,2,3], index=[0,1,2])원하는 위치에 해당값을 대입할 수있다
- frame[‘~~’]=frame.~~==‘~~’ 로 불리언값을 대입할 수있다
- del frame[‘~’]로 삭제 할 수 있다.
- frame.T 로 데이터를 전치할 수 있다.	]
>중첩된 사전 대입	
- [중첩된 사전을 DataFrame에 넘기면 바깥에 있는 사전의 키는 컬럼이 되고 안에 있는 키는 로우가 된다. ]

>DataFrame생성 데이터 종류 	
- [P.298]

>색인객체			
- [indexObj = Series객체.index 색인(인덱스)와 관련된 정보를 저장하는 객체,값 변경이 불가능하다
- pd.Series([~~], index = indexObj) 색인객체를 이용해서 색인생성 가능
- 판다스의 인덱스는 중복된 값을 허용한다-> 중복된 값 선택시 해당하는 값을 모두 선택한다]
>색인객체 메서드		
- [P.311]

# 7주차 pandas 핵심기능1
>재 색인(reindex)	
- [Series,DataFrame 객체를 새로운 색인에 맞도록 새로 생성하는 함수, 원래있던 색인은 값이 유지됨
- obj = obj.reindex([~~~], method=‘~~’) : 새로운 색인을 재배치, 존재하지 않는 색인 값은 NaN을 추가
- method =‘ffill or bfill’ 비어있는 값을 앞,뒷 값으로 채워넣는다
- DataFrame은 로우,컬럼 둘다 변경 가능하다
- frame = frame.reindex([‘1’,~~]) 하거나 frame.reindex(columns=strlist)]
>재 색인함수 인자	
- [P.324]
>색인 삭제			
- [SeriesObj = obj.drop(‘~’, ’~’) 해당 인덱스 값을 삭제 함
- DataFrameObj = obj.drop(‘~’, axis=1 or 0) 0:컬럼값(columns) 1:로우값(index)
- obj.drop(‘~’, inplace=True] inplace는 객체반환이 아닌 원본객체를 변경한다

>Series,Numpy차이	
- [Numpy는 list,  Series은 dict 이고
    1. 문자열색인도 정수색인으로 선택가능(Series[‘a’]=Series[0])
	2. 정수,문자열로도 슬라이싱 할수 있다,(Series[‘a’:’c’]=Series[0:3])	@라벨(문자열)은 마지막 슬라이싱까지 포함@
	3. 색인에 비교연산자로 불리언값 반환]
>DataFrame색인	
- [값이 뭐든 원하는 조건의 값만 골라서 가져올수 있겠다
	1. data[‘라벨’] : 해당 컬럼값을 인덱스와 함께 모두 반환 @ 밸류,문자열
	2. data[:2] : 해당 인덱스의 값을 컬럼값과 함께 모두 반환 @ where,정수
	3. data[data[~]>3] : 조건을 만족하는 값의 행렬 ‘전부’ 반환
	4. data < 5 : 블리언 표 반환/ data[data<5] =0 : True값만 0대입후 반환
	5. data.loc[‘a’(열),[’one’,’two’](행)] : 문자열색인, ‘a’열의 ‘one’, ’two’행 @슬라이싱적용가능
	6. data.iloc[[3,4](행),[1,2](열)] : 정수색인, 각3,4행의 1,2열 @ 슬라이싱적용가능	
	- p.344 : 값 선택하기]
>Pandas의 정수색인	
- [Pandas는 라벨 색인을 찾는 데 실패하면 정수 색인으로 값을 찾는다 
- loc과 iloc를 사용하는 것을 지향해야한다 @@ loc[:1]=[1,2] / iloc[:1]=[1] @@ ]

>Pandas의산술연산	
- [다른 색인을 가지고 있는 객체간에 연산을 하면 짝이 맞지않는 색인은 NaN값으로 통합된다
- obj.add(obj2, fill_value = 0) : 연산에서 NaN 값은 0을 대입 짝이 맞지않으면 0과 연산후 반환
- 2차원과 1차원의 연산은 짝이맞는 1차원의 열 값을 2차원 각 행의 열 마다 적용해서 연산한다
- P.261 산술연산 메서드]

- 행,열 정리
    - axis (0=row,index=행=1행(가로)=같은열,다른행연산,1행+2행+3..=[i][0]) -> 열 계수만큼의 결과
    - axis (1=column=열=1열(세로)=같은행,다른열연산,1열+2열+3..=[0][i]) -> 행 계수만큼의 결과

# 8주차 
1. DataFrame함수적용과 매핑 
2. 색인기준,값 기준 정렬방법, 순위 
>apply,map		
- [DF.apply(함수, axis=) : 객체를 함수에 인자로 1차원리스트를 반환 브로드캐스팅해서 열,행단위 연산 한다
- DF.applymap(함수) : 각각의 원소를 순서대로 하나씩 모두 연산한다(벡터화)
    - @@ 시리즈객체에는 map()을 사용한다, 같은 원리]
>정렬				
- [객체.sort_index(axis=,ascending=T/F) : 로우나 컬럼의 색인을 알파벳순으로 정렬하고 새로운객체로 반환
- .sort_values(by =[‘a’,’b’): 입력된 컬럼들의 원소값을 정렬]
>순위(rank) 		
- [.rank(method=메소드, ascending=F/T) : 1부터 배열의 유효한 데이터 개수까지 순서를 매긴다
- 원본객체의 인덱스에 순위를 값으로 가진 객체를 반환한다, 값이 순위값으로 바뀐다고 생각하면됨 
- 2,3등 동률일 경우 평균인 2,5를 순위 값으로 해당인덱스에 대입한다
- P.385 - 동률을 처리하는 메소드]

>중복 색인			
- [obj.index.is_unique / Series객체는 중복된 색인값이 존재할 수 있기 때문에 유일한 값인지 확인해준다
- 중복된 색인 값을 접근할 때는 중복되는 모든 값을 Serise형 으로 반환 ]
>통계계산,요약		
- [Pandas객체는 통계메서드(로우나 컬럼의 단일값을 구하는)를 가진다,
- Numpy의 동일메서드와 다르게 NaN값은 제외하도록 설계되었다
- obj.sum(axis=,skipna=T/F) /  행,열들간 원소값들을 더해서 반환한다
- skipna : T-NaN(결측치)값을 제외시키고 계산한다, F-NaN값이 포함됬을때 결과값도 NaN
- ₩P.403 요약,통계메서드 ]


# 8-3 상관관계와 공분산/ 유일 값, 값 세기, 멤버심

- ## 상관관계(Correlation)
    - 결과 값이 1가까울 수록 A값과 B값이 비례한다
    - 결과 값이 -1에 가까울 수록 A값과 B값이 반 비례한다
    
- ## 공분산(Coavariance)
    - 확률변수가 절대적인 크기에 영향을 받지않도록 일정하게 만드는 것

```py
import pandas_datareader.data as web
# 주가정보를 다운로드 받을 수 있게해주는 라이브러리
all_data = {ticker: web.get_data_yahoo(ticker)
        for ticker in ['AAPL', 'IBM', 'MSFT', 'GOOG', 'TSLA', 'AMZN']}
price = pd.DataFrame({ticker: data['Adj Close'] 
    # Adj Close : 수정 종가
        for ticker, data in all_data.items()})

volume = pd.DataFrame({ticker: data['Volume']
        for ticker, data in all_data.items()}) 
    # 'Volume : all_data에 저장된 종목들의 거래량

returns = price.pct_change()# 퍼센트_체인지
# price에 저장되어있는 주가의 퍼센트 변화율을 반환한다
returns.tail()
# 마지막 5일간의 정보를 반환한다

returns['MSFT'].corr(returns['IBM'])
# .corr() 두객체의 상관관계를 계산하는 메서드
# 상관관계가 1에 가까울 수록 두 주가가 같이 올라가고 같이내려가고, -1에 가까울수록 반비례해서 움직인다는 뜻

returns['MSFT'].cov(returns['IBM'])
# .cov() 두객체의 공분산을 구하는 메서드

returns.corr()
returns.cov()
# 저장된 정보들 의 상관관계, 공분산을 반환

returns.corrwith(returns.IBM)
# .corrwith(): Series,DataFrame과의 상관관계를 계산

returns.corrwith(volume)
# 거래량의 퍼센트 변화율에 대한 상관관계를 계산한다

```
- ### 유일 값, 값 세기, 멤버십
```py
obj = pd.Sries(['c','a','d','a','a','b'])

uniques = obj.unique()
# .unique() : 유일 값을 정렬하지 않고 반환

obj.value_counts()
# .value_counts() : Series에서 중복된 값이 몇개인지 계산

pd.value_counts(obj.values, sort=False)
# 정렬되지 않은 순서로 반환

mask = obj.isin(['b','c'])
# .isin() : 어떤 값이 Series에 존재하는지 각 인덱스를 불리언 벡터로 반환한다.
obj[mask]
# True 값인 인덱스만 반환

```

# 9. 데이터 로딩과 저장, 파일형식
- pandas의 파일 파싱 함수
    - read_csv : 파일, URL 또는 파일과 유사한 객체로부터 구분된 데이터를 읽어 온다. 데이터 구분자는 쉼표(,)를 기본으로 한다.
    - read_table : 파일, URL 또는 파일과 유사한 객체로부터 구분된 데이터를 읽어 온다. 데이터 구분자는 탭('\t')을 기본으로 한다.
    - read_excel : 엑셀 파일에서 표 형식의 데이터를 읽어 온다.
    - read_html : HTML 문서 내의 모든 테이블의 데이터를 읽어 온다.
    - read_clipboard : 클립보드에 있는 데이터를 읽어 온다.
    - read_hdf : pandas에서 저장한 HDF5(binary파일)데이터를 읽어온다
    - JSON 문자열에서 데이터를 읽어온다
    - read_sql : SQL 쿼리 결과를 pandas의 DataFrame 형식으로 읽어온다. 

- pandas파일 파싱함수의 주요 옵션
    - 색인 
        - 반환하는 DataFrame에서 하나이상의 컬럼을 색인으로 지정할 수 있다
        - 파일이나 사용자로부터 컬럼 이름을 받거나 아무것도 받지 않을 수 있다
    - 자료형 추론과 데이터 변환
        - 사용자 정의 값 변환과 비어있는 값을 위한 사용자 리스트를 포함한다.
    - 날짜 분석
        - 여러 컬럼에 걸쳐 있는 날짜와 시간 정보를 하나의 컬럼에 조합해서 결과레 반영한다.
    - 반복 
        - 여러개의 파일에 걸쳐 있는 자료를 반복적으로 읽어 올 수 있다.
    - 정제되지 않은 데이터 처리
        - 로우나 꼬리말, 주석 건너뛰기 또는 천 단위마다 쉼표로 구분된 숫자 같은 것들의 처리

-  *타입추론*
    - pandas.read_csv 같은 함수들은 데이터 형식에 자료형이 포함되어 있지 않은 관계로 타입 추론을 수행한다.

- ###  *텍스트 파일에서 데이터 읽고 쓰기*

    - 먼저 OS의 type명령을 써서 csv파일의 내용을 살펴본다
    ```py
    !type examples\ex1.csv
    # 윈도우
    !cat examples/ex1.csv
    # 리눅스, 유닉스
    ```
    - 쉼표로 구분된 텍스트 데이터 파일은 read_csv 함수를 사용해서 DataFrame으로 읽어올 수 있다.
    ```py
    df = pd.read_csv("/ex1.csv")
    ```
    - 쉼표로 구분된 텍스트 데이터파일은 read_table 함수에 구분자(sep옵션)을 지정해서 DataFrame으로 읽어 올 수 있다.
    ```py
    pd.read_table('ex1.csv', sep=',')
    ```
    - 텍스트 파일에서 DataFrame으로 데이터 읽어 올 때 색인 지정하기
    ```py
    pd.read_csv('ex1.csv', header=None)
    # 로우,컬럼 값이 0,1,2,... 로 생성
    pd.read_csv('ex1.csv', names=['a','b','c','d'], index_col = 'd')
    # names으로 컬럼색인을 생성하고 index_col으로 입력한 컬럼의 값을 인덱스 색인으로 사용할 수 있다.
    ```
- 계층적 색인
    ```py
    pd.read_csv('ex.csv', index_col=['a','b'])
    # 인덱스색인 값을 2개의 계층으로 나눠서 사용 할 수 있다
    # 'a'컬럼 값이 같은 것끼리 묶어서 'b'컬럼값을 정렬한 2계층 인덱스색인이 생성된다
    # 예제
    #       c d f
    # a b 
    # 1 x / 1,2,3
    #   y / 2,4,6
    # 2 z / 1,5,7
    #   q / 2,5,8
    ```
- 구분자없이 공백,다른패턴으로 필드를 구분한 경우
    ```py
    pd.read_table('ex1.txt', sep='\s+')
    # 공백,다른패턴일 경우 '\s+'가 자동적으로 데이터를 구분 시킨다
    ```
- 그 외의 read_csv,reac_table의 함수인자
    - skiprows : 파일의 시작부터 무시할 행의 수 또는 무시할 로우번호가 담긴 리스트
    - na_values : NA값으로 처리할 값들의 목록(컬럼값은 리스트, 컬럼의 특정값은 사전으로 지정한다)
    - comment : 주석으로 분류되어 파싱하지 않을 문자 혹은 문자열
    - thousand : 숫자를 천단위로 끊을 때 사용할 ',' '.' 같은 구분자

- # ***9-2 학습내용***
    - 텍스트 파일 조금씩 읽어오기
    - 데이터를 텍스트로 기록하기
    - 구분자 형식 다루기

### 데이터 출력 설정
```py
pd.options.display.max_rows = 10
# 큰 파일은 자료가 방대하기 때문에 
# 시작5줄+끝5줄씩만 출력하도록 설정

pd.read_csv('~', nrows=5)
# nrows 처음5줄만 출력

chunker = pd.read_csv('~', chunksize=1000)
# 파일을 여러조각으로 나눠서 읽는다
# 1000개씩 나눠서 출력, 나눠진 갯수만큼 iterable한 객체

tot = pd.Series([])
# 중복된 값 세기
for piece in chunker:
    tot = tot.add(piece['key'].value_counts(). fill_value=0)
# 'key' 컬럼의 모든 값을 비교 중복되는 값의 횟수를 반환, 없는 값은 0으로 처리
```
### csv파일 저장하기
```py
# DataFrame을 ','를 구분자로 쓰는 csv로 저장
data.to_csv('dir')

# 파일 기록이 아닌 콘솔에서 출력
import sys
data.to_csv(sys.stdout, sep='|', na_rap='NULL', index=False, header=False)
# na_rap 은 비어있는 값에 넣을 값
# index=False 는 로우색인 삭제
# header=False 는 컬럼색인 삭제

data.to_csv('~', columns=['a','b','c'])
# 입력한 컬럼의 값만 저장한다

dates = pd.date_range('1/2/2021', periods=7)
# 입력한 날짜부터 7번째 날까지 반환  
```

### 구분자 형식 다루기
```py
# 파이썬 내장 모듈
import csv
# 구분자가 한 글자인 파일을 csv.reader함수를 사용해서 읽을 수 있다.
f = open('~.csv')
reader = csv.reader(f)
 
```
#
- ## ***9-3 학습내용***
    - 이진 데이터 형식
    - pickle의 직렬화
    - HDF5파일 형식
    - 엑셀자료 읽어오기
    - 데이터 베이스와 함께 사용하기

### pickle 직렬화
- 직렬화는 이진형식의 데이터로 저장하는 것이다
```py
Dataframe.to_pickle('/frame_pickle')
# to_pickle 메서드로 바이너리 데이터를 저장한다

pd.read_pickle('/frame_pickle')
# read_pickle 메서드로 읽어올수 있다

# pickle 직렬화는 추후 라이브러리 버전이 올라갔을 때 지원되지 않을 수 있기때문에 그다지 권장되지 않는다
```

### HDF5 형식
- 대량의 과학 계산용 배열 데이터를 저장하기위해 고안된 바이너리 형식의 파일포맷
- 파이썬 뿐만 아니라 C,Java 등 여러 언어에서 지원
- 다앙한 압축 기술을 사용해서 실시간 압축을 지원한다
    - 반복되는 패턴을 가지는 데이터를 효과적으로 저장할 수 있다

- ***pandas는 HDFStore 클래스를 통해 객체를 저장할수 있다***
    ```py
    frame = pd.DataFrame({'a':np.random.randn(100)})

    # HDF를 저장할 파일 객체 선언
    f_obj = pd.HDFStore('mydata.h5')

    # 파일객체에 사전형태로 pd객체 저장
    f_obj['obj1'] = frame

    # 원하는 행,열만 저장 (Series)
    f_obj['obj1_col'] = frame['a']

    ```
- HDFStore의 2가지 저장 스키마
    - fixed
        - 디폴트 값으로 사용된다
        - 파일을 저장,불러오는 기능 
    - table
        - 쿼리연산을 지원한다
        - 데이터의 일부를 조회해서 가져올 수 있다
        - 연산이 좀 더 느리다
    ```py  
    # table로 저장된 자료만 쿼리연산을 할수 있다
    f_obj.put('obj2', pd_obj, format='table')
    # put(파일명, 객체, format='table')로 저장

    # 쿼리연산으로 데이터 불러오기
    f_obj.select('obj2', where=['index >= 10 and index <= 15'])
    # select(파일명, where=index)로 불러올 수 있다

    # 파일 닫기
    f_obj.close()


    # table 스키마의 다른 저장,불러오기메서드
    frame.to_hdf('data.h5', 'obj3', format='table')
    # to_hdf(파일명, 키값, 포맷)으로저장
    pd.read_hdf('data.h5', 'obj3', where=['index<4'])
    # read_hdf(파일명, 키값, where)
    ```
### 엑셀 파일 읽어오기
- xls, xlsx 확장자의 파일을 읽어온다
- 엑셀파일 읽기
    ```py
    # 엑셀 파일객체 생성
    xl_obj = pd.Excelfile(파일명.xlsx)
    # Excelfile() 엑셀파일을 파일객체로 반환
    
    # 엑셀 시트 불러오기
    pd.read_excel(xlsx, 'Sheet1')
    # read_excel() 해당시트값들을 반환
    # 시트명이 파일과 일치해야 한다
    
    # 파일에서 시트의 값 바로가져오기
    frame = pd.read_excel(파일명.xls, 'Sheet1')
    # 파일객체를 생성하지 않고 해당 시트의 값을 바로 가져온다
    ```
- 엑셀 파일 저장
    ```py
    # 데이터 저장
    xl_obj = pd.Excelwriter(파일명.xlsx)
    # Excelwriter()메서드로 저장할 파일위치를 객체로 생성
    frame.to_excel(xl_obj, 'Sheet1')
    # to_excel(객체, 시트) 데이터를 파일객체 어느 시트에 저장할지 선언
    xl_obj.save()
    # 객체에 선언된 값 저장


    # 데이터 엑셀에 바로 저장하기
    frame.to_excel(파일명.xlsx)
    # 데이터가 디폴트 시트에 바로 저장된다
    ```
### 데이터베이스와 함께 사용하기 
- 관계형 데이터베이스에서 SQL로 데이터를 읽어와서 DataFrame에 저장할 수 있다
- 파이썬 내장 sqlite3 드라이버를 이용해서 SQLite 데이터베이스를 이용할 수 있다
    
    ```py
    import sqlite3
    
    # 쿼리 언어를 사용해서 값 선언
    query1 = """.CREATE TABLE test
    (a VARCHAR(20), b VARCHAR(20),
    c REAL, d INTEGER);"""
    # a,b,c,d 4개의 컬럼 생성
    # 각 컬럼의 자료형 선언

    # 만들어진 TABlE을 삭제하는 값
    query2 = "DROP TABLE test"

    # DB와 연결하기위해 경로객체를 생성
    con = sqlite3.connect('mydata.sqlite')
    # connect(경로명) DB와 연결할 경로명을 선언

    # 경로객체를 통해서 쿼리값 전달
    con.execute(query1)
    # 경로객체.execute(쿼리값) DB에 쿼리를 보낸다

    # 실행된 결과값 확인
    con.commit()

    # 실행 취소
    con.rollback()


    # 생성된 test테이블에 데이터 입력
    data = [('a','b',1.2,5),
        ('c','d',1.2,5),
        ('x','y',1.2,5)]
    
    # 쿼리언어 명령어 선언
    stmt = "INSERT INTO test VALUES(?, ?, ?, ?,)"
    # 컬럼 개수만큼 (?) 추가

    # 데이터 저장
    con.excutemany(stmt, data)
    #excutemany(명령어, 값) TABLE에 값저장

    # 입력된 값 실행
    con.commit()

    # 값 불러오기
    cursor = con.execute('select * from text')
    # select * 모든 값 가져오기
    # *에 행의 위치를 넣을 수 있다
    # cursor는 조회한 데이터를 임시로 보관하는 
    # 곳이다(장바구니 같은의미)

    rows = cursor.fetchall()
    # fetchall() 메서드로 
    # cursor에 저장된 값을 튜플리스트형태로 반환한다

    # 값의 여러가지 속성확인
    cursor.description
    

    ```

# 10. 데이터 정제 및 준비
- ## 10-1 학습내용
    - pandas 누락된 데이터 처리 함수, 제외하기
    - pandas 결측치(NaN) 채우기

누락된 데이터 처리하기
- pandas객체는 모든 기술 통계에서 결측치는 배제하고 처리한다

- 산술 데이터는 누락된 데이터를 NaN으로 취급한다
```py
from numpy import nan
string_data = pd.Series(['a','b',np.nan])
# np.nan은 NaN(null)으로 처리된다
```

- R프로그래밍 언어에서는 결측치를 NA로 정의한다
> 결측치
- NA, null, NaN, None 같은 값이다

NA처리 메서드
- *dropna* : 누락된 데이터가 이는 축(로우,컬럼)을 제외
- *fillna* : 누락된 데이터를 대신할 값을 채우거나 'ffill' 이나 'bfill' 같은 보간 메서드를 적용
- *isnull* : 누락되거나 NA인 값을 찾아서 블리언 값이 저장된 같은 형의 객체로 반환
- *notnull* : isnull과 반대되는 메서드



```py
from numpy import nan as NA
# NA 로 명을 바꿈

# 결측치 제외하기
data = pd.Series([1,NA,2,NA])
data.dropna()
# 결측치를 빼고 반환

data[data.notnull()]
# 결측치가 아닌 값만 참을 반환해서 값을 반환

data = pd.DataFrame([[1,NA,2,NA],
                     [NA,1,2,NA]])
data.dropna()
# 결측치가 포함된 행은 전부 제외하고 반환
data.dropna(how=all, axis=1)
# axis=1 열을 기준으로연산(디폴트는 행)
# how=all 축(행,열)의 값이 전부 결측치 일때만 제외

data.dropna(thresh=1)
# thresh=1 축의 값이 1개 이상 이면 반환


# 결측치 채우기
data.fillna(1)
# 결측치를 1로 채운다
data.fillna({1:2,2:1})
# 1열은 2를, 2열은 1을 채운다
data.fillna(method='ffill', limit=2, inplace=True)
# method='ffill'은 이전 축의 값으로 채운다, 'bfill'은 뒤의 축의 값으로 채운다
# limit=2 값을 앞 혹은 뒤부터 몇개까지 채울지 결정
# inplace=True 는 원본객체의 값을 바꾼다(디폴트는 False)

```

## 10-2 학습 내용
- DataFrame 중복 제거하기
- DataFrame 컬럼,Series 배열 내의 데이터 변형하기
- Series객체 값 치환하기

### 중복값 제거하기

```py
import pandas as pd
import numpy as np

data = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'],'k2': [1, 1, 2, 3, 3, 4, 4]})

print(data.duplicated())
# duplicated() 로우(행)값이 전부 중복인지 아닌지 
# 블리언 Series객체반환

print(data.drop_duplicates())
# drop_duplicates() 중복된 로우(행)이 제거된 
# DataFrmae객체를 반환

data['v1'] = range(7)
print(data.drop_duplicates(['k1']))
# ['k1']컬럼에서 중복되는 값을 가진 로우는 전부 삭제

print(data.drop_duplicates(['k1', 'k2'], keep='last'))
# keep = 'last' 중복되는 값중 나중에 인덱스 값을
#  살리고 이전 값을 삭제

```

### 함수나 매핑을 이용해서 데이터 변형하기

```py
data = pd.DataFrame({'food': ['A', 'B', 'A', 'C', 'D', 'a', 'd'],
                     'ounces': [4, 3, 12, 6, 7.5, 8, 3]})

str_to_food = {
    'A': 'Apple',
    'B': 'Banana',
    'C': 'Candy',
    'D': 'Do'
}

uppercased = data['food'].str.upper()
# str.upper(),lower() 해당 컬럼의 문자열을 대,소문자로 변환

data['animal'] = uppercased.map(str_to_food)
# pandas.map(사전) pd의 1차원 배열값을 
# 함수가 아닌 사전의 키값으로 대입해서 연결된 밸류를 반환한다
# 데이터의 요소별 변환 및 데이터를 다듬는 작업을 편하게 수행

data['food'].map(lambda x : str_to_food[x.upper()])
# map(a, b)가 아니라 b.map(a)형식으로 
# 사전키값이 아닌 함수로 대입을 했다
```

## 값 치환하기

```py
data = pd.Series([1., -999., 2., -999., -1000., 3.])
print(data.replace(-999, np.nan))
# replace([a],[b]) 같은 인덱스의 a값을 
# 전부 같은 인덱스의 b값으로 바꾼다, {a:b}사전형도 가능
```

## 10-3 학습내용
- 축 색인 이름 바꾸기
- 개별화와 양자화
- 연속성 데이터 구간별로 구분하기
- Categorical 객체
- cut, qcut함수

## 축 색인 이름 바꾸기
- DataFrame은 축이름을 함수나 다른 변수를 이용해서 바꿀 수 있다
```py
import numpy as np
import pandas as pd

data = pd.DataFrame(np.arange(12).reshape((3, 4)), index=[
                    'a', 'b', 'c'], columns=[1, 2, 3, 4])

def tranform(x): return x.upper()
data.index = data.index.map(tranform)
# map을 이용해서 index값만 함수에 
# 넣어서 변환후 다시 index에 대입했다


print(data.rename(index=str.title, columns=str.upper))
# rename(index,columns)로 간단하게 색인 값을 변경할 수 있다
# str은 원본값을 의미 title은 문자열의 첫글자만 대문자로 만드는 메소드

data.rename(index={'a': 'AA'}, columns={'one': 'first'}, inplace=True)
# 사전형으로 색인값 변환, inplace로 원본객체를 바꿘다
```

## 개별화와 양자화
- 연속성데이터는 필요에 따라 개별로 분활하거나 분석을 위해 그룹별로 나눌 수 있다

- ## Categorical 객체
    - 각 데이터가 속하는 *카테고리의 번호*를 배열로가지는 codes 속성
    - Interval Index객체로서 *분류 간격에대한 정보*를 가지는 categories속성 

```py
ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]

bins = [18, 25, 35, 60, 100]
cats = pd.cut(ages, bins)
# bins의 [0],[1]로 하나의 카테고리 생성 (18, 25] 18초과, 25이하
# cut(대입할시퀀스, 기준값시퀀스) 기준값으로 대입한 값이 어떤 카테고리에 속하는지 연산후,
# 카테고리 값을 대입한값의 인덱스와 같게 반환한다(Categorical 객체)

print(cats.codes)
# 데이터가 속한 카테고리의 인덱스를 값으로 반환
print(cats.categories)
# 기준이되는 카테고리를 반환
print(pd.value_counts(cats))
# 카테고리별로 몇개의 value를 가지고 있는지 반환

pd.cut(ages, [15, 24, 36, 57, 100], right=False)
# right=False 는 (]초과,이하 -> [)이상,미만 으로 바뀐다

group = ['Youth', 'YoungAdult', 'MiddleAged', 'Senior']
print(pd.cut(ages, bins, labels=group))
# 카테고리 인덱스와 같은 labels인덱스의 값을 대신 반환한다

print(pd.cut(ages, 4, precision=2))
# precision=2 는 소수점 2자리까지 표시한다
# 카테고리값이 아니라 그룹의 개수(4)를 넘겨주면 
# 최소값과 최대값을 기준으로 균등한 길이의 그룹을 자동계산

data = np.random.randn(1000) # 정규 분포
cats = pd.qcut(data, 4)     # 4분위로 분류
# qcut은 각 그룹의 데이터수가 비슷하도록 카테고리를 나눠준다
print(pd.value_counts(cats))
# 각 그룹이 250개의 데이터를 가짐

pd.qcut(data, [0, 0.1, 0, 5, 0.9, 1.])
# 각 그룹의 데이터수를 퍼센트 별로 따라서 나눠준다
```

## 11-1 학습내용
- matplotilb라이브러리
- 기본 그래프 그리기/ *plt.plot*
- 그래프에 색상,선,마커 옵션 추가/ *'r*:'

> matplotlib 
- 파이썬에서 2D 형태의 그래프, 이미지 등을 그릴 때 사용
- 실제 과학 컴퓨팅 연구 분야나 인공지능 연구분야에서 많이 활용

## mataplotlib
- pyplot 모듈 사용하기
    ```py
    import matplotlib.pyplot as plt

    plt.plot([10, 20, 30, 40],'red' , lebel='asc')
    # plot() x 좌표는 인덱스, y좌표는 값으로 표현
    # lebel='asc' 범례(그래프선에 이름을 정의)를 표시
    # color='red' 그래프선의 색 정의
    plt.legend(loc=1)
    # 1,2,3,4: 모서리
    # (5,7),6,8,9: 왼,오,위,아래
    # 해당 위치에 범례를 표시 ,5가 디폴트
    plt.show()
    # 설정한 그래프를 보여준다


    plt.title('graph2')
    # title() 그래프에 이름을 지정
    plt.plot([1, 2, 3, 4], [12, 4, 7, 96],'r:')
    # plot() 첫 인수는 x좌표, 둘째 인수는 y좌표 각 좌표데이터의 개수가 같아야한다
    # 'r:'은 red 점선이라는 의미
    # 'y--'로 yellow 실선을 만들수도있음
    plt.show()


    # 마커로 그래프그리기
    plt.title('marker')
    plt.plot([10, 20, 30, 40], 'r*')
    # 'r*' red 별 모양
    plt.plot([1, 2, 3, 4], 'b>:')
    # 'b>' blue, 방향표 모양,점선
    plt.show()
    ```

## 11-2 학습내용
- 기온 공공데이터 다운로드 받기
- 데이터 읽어오기, 시각화
- 날짜 데이터 추출하기

```py
import matplotlib.pyplot as plt
import csv

f = open('/Users/gimjuyeong/myproject/study/suncheon.csv', encoding='euc-kr')
# 자료에 따라 인코딩 해주기
data = csv.reader(f)
next(data)
# 이터레이터 객체의 이터레이션을 한번 넘겨서 
# 불필요한 데이터를 삭제한다
result = []
date = []
for row in data:
    if (month := row[0].split('.')[1]) == '11':
        result.append(float(row[-1]))  # 기온

plt.figure(figsize=(15, 5))
# figure(figsize=()) 그래프사이즈 인치기준
plt.plot(result,  'r')
plt.show()

f.close()
```

# 11-3 학습내용
- 히스토그램
- 데이터를 히스토그램으로 표현하기
- 데이터를 boxplot으로 표현하기

## plt.hist() 함수
- 히스토그램은 자료의 빈도를 직사각형 모양의 막대 그래프로 나타낸것
- 기온분포도
    ```py
    import matplotlib.pyplot as plt
    import csv

    f = open('/Users/gimjuyeong/myproject/study/suncheon.csv', encoding='euc-kr')
    data = csv.reader(f)
    next(data)

    result = (float(row[-1]) for row in data)
    # 기온의 분포를 확인 할 수 있다
    plt.hist(list(result), bins=100)
    # hist() : 분포상태를 막대그래프로 표현 
    # bin= : 가로축 구간의 개수를 설정
    
    plt.show()
    f.close()
    ```
## boxplot
- 데이터의 빈도를 상자 그림으로 시각화한다
- matplotlib.pyplot.boxplot()
    - 최대값, 최소값, 상위 1/4, 2/4(중간), 3/4에 위치한 값을 보여주는 박스 그래프이다
    ```py
    # ~~ 계속
    result = (float(row[-2]) for row in data) # 최저기온
    plt.boxplot(list(result), showfliers=False)
    # boxplot() : 분포도를 박스그래프로 표현
    # showfliers=False : 아웃라이어 생략
        # outlier : 다른 수치에 비해 너무 크거나 
        # 작은 값을 자동으로(원으로) 나타낸다
    plt.style.use('ggplot')
    # 그래프 스타일 지정
    plt.figure(figsize = (10, 5), dpi=300)
    # 그래프 크기 지정
    plt.show()
  

    ```
    - 복수의 리스트를 그릴때는 다시 리스트로 감싸서 대입해야한다/ [x, y]

# 12-1 학습내용
- 인구 공공데이터 내려받기
- 우리동네 인구구조 조사하기

```py
import matplotlib.pyplot as plt
import pandas as pd
import csv


def get_int(x):
    if "," in x:
        return int(x.replace(",", ""))

with open(
    "/Users/gimjuyeong/myproject/study/202110_202110_연령별인구현황_월간.csv", encoding="euc-kr"
) as f:
    data = list(csv.reader(f))
print([age.split("_")[-1] for age in data[0][229:240]])
print(data[1][126:136])

man_popu = [get_int(i) for i in data[1][126:136]]
woman_popu = [get_int(i) for i in data[1][229:239]]
ages = [age.split("_")[-1] for age in data[0][126:136]]
plt.plot(ages, man_popu, "b:")
plt.plot(ages, woman_popu, "r:")
plt.rc("font", family="Malgun Gothic")  # 타이틀에 font에대한 family속성 지정
plt.title("shucheon 20ages man,woman population")
plt.show()
```

# 12-2 학습내용
- 막대 그래프 그리기, bar()
- 항아리 모양 그래프 그리기


### 막대 그래프 그리기
- bar()
    ```py
    import matplotlib.pyplot as plt

    plt.style.use('default')
    plt.figure(figsize=(6,3))
    plt.bar([0, 1,2,4,6,10],range(6))
    # bar() 길이가 같은 시퀀스 x, y를 둘다 입력해야 한다
    # range()함수를 사용할 수 있다
    plt.show()

    plt.rcParams('axes.Unicod_minus'=False)
    # 음의부호(-)가 깨지지 않도록 설정한다
    ```

- barh()
    - 막대그래프를 수평으로 그린다



# 학습내용 12-3
- 파이 차트 그리기
- 성별 인구 비율 그리기


- pie()
```py
import matplotlib.pyplot as plt
plt.rc('font', family='Malgun Gothic')
# 글 꼴을 정의한다
plt.pie([population.man, population.woman], labels=['man', 'woman']
, autopct='%.2f%%', colors=['skyblue', 'pink'], explode=[0, 0.1], startangle=90)
# pie([값], labels=[값명], autopct='퍼센트'(%%는 %를 출력하기위해 작성), 
# colors=[색]), explode=([파이 자르기 0~1]), starangle=int x도 만큼 원을 돌린다
plt.axis('equal')
# 정 원을 그린다
plt.show()
```

# 13-1 학습내용
- 대중교통 데이터 시각화
- 시각화 데이터저장

### 데이터 시각화
- 데이터를 csv파일로 저장후 필요없는 정보의 열을 삭제, 숫자형 자료에서 ',' 를 없에고 저장
```py
with open('데이터/subwayfee.csv') as f:
    data = csv.reader(f)
    next(data)
    label = ['유임승차', '무임승차']
    for row in data:
        for i in range(4,8):
            row[i] = int(row[i])       
        plt.pie([row[4],row[6]], labels=label, autopct='%1.f%%')
        plt.show()
```

# 13-2 학습내용
- 지하철 시간대별 데이터 시각화

# 14-1 학습내용
- numpy를 활용해서 히스토그램, 삼각함수, 버블차트 그리기

### np.random.choice
```py
# dice = [random.randint(1,6) for _ in range(10)]

# numpy 사용
dice = np.random.choice(6,100, p=[0.1, 0.1, 0.2, 0.4, 0.1, 0.1])
# choice(최대값, 배열길이, p=확률분포, replace=T/F)
plt.hist(dice, bins=6)
plt.show()
```

### 삼각함수
```py
a = np.arange(-np.pi, np.pi, np.pi/100)
# -3.14 부터 3.14까지의 값을 100개로 나눈다
plt.plot(a, np.sin(a))
plt.show()
```

### 버블차트
```py
 버블차트
# np.scatter(x축, y축, s=마커크기각각설정, c=마커색변화기준, cmap=색변화 alpha=투명도)

x = np.random.randint(10, 100, 200)
y = np.random.randint(10, 100, 200)
# randint(최소값, 최대값, 배열길이)
size = np.random.rand(200) * 100


plt.scatter(x, y, s=size, c=x, cmap='jet', alpha=0.7)
plt.colorbar()
plt.show()
```

# 14-2 학습내용
- 특정 지역의 인구구조와 비슷한 인구구조가진 지역 찾기

### 인구구조 비교
- 알고리즘
    - 전국 모든지역중 비교지역 B를 선택
    - 특정 지역 A의 0세 인구 비율에서 비교할 지역 B의 0세 인구비율를 뺸다
    - 100 세까지 반복후 각각 차이를 모두 더한다
    - 모든 지역에 반복, 차이가 적은 지역을 찾는다

```py
def search_population(populatino_list: csv):
    searched_population = namedtuple('searched',('man','woman'))
    searched_area = input('검색을 원하는 지역')
    
    for row in populatino_list:
        if searched_area in row[0]:
            edited_man = row[18:31]
            edited_woman = row[33:46]
            population = searched_population(edited_man, edited_woman)
            
    # 시각화
    plt.plot(range(18,31),population.man)
    plt.plot(range(18,31),population.woman)
    plt.figure(figsize=(10,5))
    plt.show()
```




# 14-3 학습내용
- pandas를 이용해서 인구구조 비슷한지역 찾기  

